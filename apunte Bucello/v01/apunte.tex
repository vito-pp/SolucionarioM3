\documentclass[a4paper]{scrartcl} %{amsart} %{article} %

\usepackage{pablo}

\title{Matem�tica 3. Notas te�ricas.}
\author{Pablo A. Bucello.}
\date{}

\hyphenation{ge-ne-ra-li-za-dos me-dian-te con-si-de-re-mos auto-va-lo-res auto-vec-to-res}

\begin{document}

\maketitle

\section{Nociones de Topolog�a.} \label{sec:topo}

 \begin{definition} [Bola de radio $\delta$ y centro $x_o$] \label{def:bola}
 Sean $x_o \in \Rn{n}, \delta > 0$ y $\dis$ una distancia en $\Rn{n}$. La \emph{bola de radio $\delta$ y centro $x_o$}, que denotamos con $B_{\delta}(x_o)$, es el conjunto:
 \[
  B_{\delta}(x_o) = \left\lbrace x \in \Rn{n} : \dis(x,x_o) < \delta \right\rbrace.
 \]
 El conjunto
 \[
  B^*_{\delta}(x_o) = B_{\delta}(x_o) - \{ x_o \}
 \]
 es la \emph{bola reducida de radio $\delta$ y centro $x_o$}.

\end{definition}

\begin{definition} [Punto interior, interior de un conjunto] \label{def:interior}
 Sean $A \subset \Rn{n} \text{ y } x_o \in A$. Decimos que $x_o$ es \emph{punto interior} de $A$ si
 \[
  \exists \delta > 0 / B_{\delta}(x_o) \subset A.
 \]
 El \emph{interior} de $A$, que denotamos con $\interior(A)$ o \AA{}, es el conjunto de todos los puntos interiores de $A$:
 \[
  \interior(A) = \left\lbrace x \in A : x \text{ es punto interior de } A \right\rbrace.
 \]
\end{definition}

\begin{definition} [Conjunto abierto] \label{def:abierto}
    Sea $A \subset \Rn{n}$. Decimos que $A$ es \emph{abierto} si
\[
     \forall x_o \in \exists \delta > 0 : B_{\delta}(x_o) \subset A.\footnote{\text{i.e.: $A$  es abierto si todos sus puntos son interiores.}}
\]
\end{definition}

\begin{propiedad} \label{prop:abierto_int} 
  Un conjunto $A \subset \Rn{n}$ es abierto si y solo si $A = \interior(A)$.
\end{propiedad}

\begin{definition} [Conjunto cerrado] \label{def:cerrado}
 Sea $A \subset \Rn{n}$. Decimos que $A$ es \emph{cerrado} si su complemento $A^c = \Rn{n} - A$ es abierto.
\end{definition}

\begin{definition} [Frontera de un conjunto] \label{def:frontera}
 Sea $A \subset \Rn{n}$. La \emph{frontera} de $A$, que denotamos con $\front A$ o $\frontera(A)$, es el conjunto:
 \[
  \front A = \left\lbrace x_o \in \Rn{n} : \forall \delta > 0 \,
  B_{\delta}(x_o) \cap A \ne \emptyset \wedge
  B_{\delta}(x_o) \cap A^c \ne \emptyset \right\rbrace.
 \]
\end{definition}

\begin{propiedad} \label{prop:cerrado_front}
 Un conjunto $A \subset \Rn{n}$ es cerrado si y solo si $\front A \subset A$.
\end{propiedad}

\begin{definition} [Punto de acumulaci�n] \label{def:pto_acum}
 Sean $A \subset \Rn{n} \text{ y } x_o \in \Rn{n}$. Decimos que $x_o$ es \emph{punto de acumulaci�n} de $A$ si
 \[
  \forall \delta > 0 \left( B_{\delta}(x_o) - \{ x_o \} \right) \cap A \ne \emptyset. 
 \]
 Denotamos el conjunto de todos los puntos de acumulaci�n de $A$ con $A'$:
 \[
  A' = \{ x \in \Rn{n} : x \text{ es punto de acumulaci�n de } A \}.
 \]

\end{definition}

\begin{definition} [Entorno de un punto] \label{def:entorno}
 Sean $N \subset  \Rn{n}$ y $x_o \in \Rn{n}$. Decimos que $N$ es \emph{entorno} de $x_o$ si
 \[
  \exists \delta > 0 : B_{\delta}(x_o) \subset N.
 \]
\end{definition}

\begin{definition} [Punto aislado] \label{def:pto_ais}
 Sean $A \subset  \Rn{n}$ y $x_o \in A$. Decimos que $x_o$ es \emph{punto aislado} de $A$ si $x_o$ no es punto de acumulaci�n de $A$.
\end{definition}

\begin{definition} [Conjunto acotado] \label{def:conj_acotado}
 Sea $A \subset \Rn{n}$. Decimos que $A$ es un \emph{conjunto acotado} si existe $\delta > 0$ tal que la bola de radio $\delta$  centrada en el origen contiene al conjunto $A$, es decir, si $\exists \delta > 0 : A \subset B_{\delta}(\mathbf{0})$.\\
 Equivalentemente, $A$ es un \emph{conjunto acotado} si $\exists \delta > 0, x_o \in \Rn{n} : A \subset B_{\delta}(x_o)$.
\end{definition}


\section{L�mite de funciones.} \label{sec:limites}
\begin{definition} [L�mite] \label{def:limite}
Sean $f:A \subset \Rn{n} \to \Rn{m}$ una funci�n, $L \in \Rn{m}$ y $x_0$ un punto de acumulaci�n de $A$. Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $L$} o que \emph{$f$ tiende a $L$ cuando $x$ tiende a $x_o$}
si
\[
 \forall \varepsilon > 0 \, \exists \delta > 0 / f(x) \in B_{\varepsilon}(L) \, \forall 
 x \in B_{\delta}^*(x_o) \cap A.
\]

En este caso, utilizamos la notaci�n
\[
 f(x) \xrightarrow[x \to x_o]{} L \quad \text{o} \quad \lim_{x \to x_o} f(x) = L.
\]
\begin{obs} Si $f$ es un \emph{campo escalar} (es decir, si en la definici�n \eqref{def:limite} es $m = 1$), la condici�n 
 \[
 \forall \varepsilon > 0 \, \exists \delta > 0 / f(x) \in B_{\varepsilon}(L) \, \forall 
 x \in B_{\delta}^*(x_o) \cap A
\]
es equivalente a 
\[
 \forall \varepsilon > 0 \, \exists \delta > 0 / \abs{ f(x) - L } < \varepsilon \, \forall 
 x \in B_{\delta}^*(x_o) \cap A.
\]
\end{obs}

\begin{obs} La definici�n de l�mite puede expresarse equivalentemente en t�rminos de distancias o de normas:
\begin{itemize} 
 \item Sean $f:A \subset \Rn{n} \to \Rn{m}$ una funci�n, $L \in \Rn{m}$ y $x_0$ un punto de acumulaci�n de $A$. Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $L$} o que \emph{$f$ tiende a $L$ cuando $x$ tiende a $x_o$} si
\[
 \forall \varepsilon > 0 \, \exists \delta > 0 / \dis_m {(f(x),L)} < \varepsilon \, \forall 
 x\in A : 0 < \dis_n {(x,x_o)} < \delta,
\] 
donde $\dis_n$ y $\dis_m$ son las distancias en $\Rn{n}$ y $\Rn{m}$, respectivamente.

 \item Sean $f:A \subset \Rn{n} \to \Rn{m}$ una funci�n, $L \in \Rn{m}$ y $x_0$ un punto de acumulaci�n de $A$. Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $L$} o que \emph{$f$ tiende a $L$ cuando $x$ tiende a $x_o$} si
\[
 \forall \varepsilon > 0 \, \exists \delta > 0 / \norm{f(x) - L}_m < \varepsilon \, \forall 
 x\in A : 0 < \norm{x - x_o}_n < \delta,
\] 
donde $\norm{\cdot}_n$ y $\norm{\cdot}_m$ son las normas en $\Rn{n}$ y $\Rn{m}$, respectivamente.
\end{itemize}
\end{obs}

\end{definition}

\begin{theorem}\textbf{Unicidad del l�mite.} \label{teo:unicidad_limite}
\mbox{}

Sean $f:A \subset \Rn{n} \to \Rn{m}$ una funci�n, $x_0$ un punto de acumulaci�n de $A$ y $L_1, L_2 \in \Rn{m}$ tales que 
\[
 f(x) \xrightarrow[x \to x_o]{} L_1 \quad \wedge \quad f(x) \xrightarrow[x \to x_o]{} L_2.
\]
Entonces $L_1 = L_2$.
\begin{proof}
\mbox{}

Las ideas utilizadas en la demostraci�n de este teorema son las que siguen.\\
Como 
\[
 f(x) \xrightarrow[x \to x_o]{} L_1,
\]
dado $\varepsilon > 0$ existe alg�n $\delta_1 > 0$ tal que cada punto $x \in B_{\delta_1}^*(x_o) \cap A$ se aplica a trav�s de $f$ en alg�n punto de la bola de centro $L_1$ y radio $\varepsilon$.

\def\Ro{2.0}
\def\Rb{1.0}
\def\Ra{3.0}
\def\sep{1.0*\Ro}

\input{fig1}


De la misma manera, como 
\[
 f(x) \xrightarrow[x \to x_o]{} L_2,
\]
dado $\varepsilon > 0$ existe alg�n $\delta_2 > 0$ tal que cada punto $x \in B_{\delta_2}^*(x_o) \cap A$ se aplica a trav�s de $f$ en alg�n punto de la bola de centro $L_2$ y radio $\varepsilon$.

\input{fig2}


Si suponemos que $L_1 \ne L_2$, por propiedad de la distancia es $\dis(L_1,L_2) > 0$ y podemos elegir 
\[
 \varepsilon = \frac{\dis{(L_1,L_2)}}{2}.
\]
Para este valor de $\varepsilon$ podemos encontrar un punto $x$ que se aplica por $f$ en alg�n punto de la bola de centro $L_1$ y radio $\varepsilon$ \textbf{y tambi�n} se aplica por $f$ en alg�n punto de la bola de centro $L_2$ y radio $\varepsilon$, lo cual es absurdo, pues estas dos bolas son disjuntas.

\input{fig3}

Ahora s�, veamos la demostraci�n formal del teorema.\\
 Supongamos, por el absurdo, que $L_1 \ne L_2$, y sea $\varepsilon = \dis(L_1,L_2)/2 > 0.$ \\ 
 Como 
 \[
  f(x) \xrightarrow[x \to x_o]{} L_1,
 \]
podemos elegir $\delta_1 > 0$ tal que $x \in B_{\delta_1}^*(x_o) \cap A \then f(x) \in B_{\varepsilon}(L_1)$.\\
Como 
\[
 f(x) \xrightarrow[x \to x_o]{} L_2,
\]
 podemos elegir $\delta_2 > 0$ tal que $x \in B_{\delta_2}^*(x_o) \cap A \then f(x) \in B_{\varepsilon}(L_2)$.\\
 Notemos que, como sugiere la figura, 
 \[
  B_{\varepsilon}(L_1) \cap B_{\varepsilon}(L_2) = \emptyset.
 \]
 En efecto, de no ser as�, sea $z \in B_{\varepsilon}(L_1) \cap B_{\varepsilon}(L_2)$. Tenemos que:
 \[
  2 \varepsilon = \dis(L_1,L_2) \le \dis(L_1,z) + \dis(z,L_2)
  < \varepsilon + \varepsilon = 2 \varepsilon \then \varepsilon < \varepsilon. \text{ Absurdo.}
 \]

 Sea $\delta = \min\{ \delta_1, \delta_2 \}$. \\
 Como $B_{\delta}^*(x_o) \subset B_{\delta_1}^*(x_o)$ y $B_{\delta}^*(x_o) \subset B_{\delta_2}^*(x_o)$, si tomamos alg�n $x \in B_{\delta}^*(x_o) \cap A$\footnote{Notemos que $B_{\delta}^*(x_o) \cap A \ne \emptyset$ porque $x_o$ es un punto de acumulaci�n de $A$.}, vale que $f(x) \in B_{\varepsilon}(L_1)$ y tambi�n $f(x) \in B_{\varepsilon}(L_2)$, por lo que $f(x) \in B_{\varepsilon}(L_1) \cap B_{\varepsilon}(L_2)$. Absurdo, pues $B_{\varepsilon}(L_1) \cap B_{\varepsilon}(L_2) = \emptyset$. El absurdo provino de suponer que $L_1 \ne L_2$, por lo cual debe ser $L_1 = L_2$.

\end{proof}

\end{theorem}
\begin{propiedad}[�lgebra de l�mites] \label{prop:alg_lim} Sean $f,g:A \subset \Rn{n} \to \Rn{m}$ funciones y $x_0$ un punto de acumulaci�n de $A$. Supongamos que 
  \begin{align*}
   &\lim_{x \to x_o} f(x) = L_1 \in \Rn{m} \\
   &\lim_{x \to x_o} g(x) = L_2 \in \Rn{m}.
  \end{align*}
  Entonces:
  \begin{enumerate} [i.]
   \item Linealidad
      \begin{enumerate} [(a)]
       \item $\lim_{x \to x_o} (f + g)(x) = L_1 + L_2$
       \item $\lim_{x \to x_o} (\alpha f)(x) = \alpha L_1 \, \forall \alpha \in \R$
      \end{enumerate}
  \item $\lim_{x \to x_o} (f \cdot g) (x) = L_1 \cdot L_2$\footnote{Si $m \ge 2$, ``$\cdot$'' representa el producto escalar en $\Rn{m}$.}
  \item Si $m = 1$ (i.e., si $f \text{ y } g$ son campos escalares), $g$ es no nula en alg�n entorno de $x_o$ y $L_2 \ne 0$, 
  \[
   \lim_{x \to x_o} \frac{f(x)}{g(x)} = \frac{L_1}{L_2}.
  \]
  \end{enumerate}
\end{propiedad}

\begin{propiedad} \label{prop:lim_x_comp}
 Sea $F: A \subset \Rn{n} \to \Rn{m}$ un campo vectorial y $x_0$ un punto de acumulaci�n de $A$. Sean $f_j: A \subset \Rn{n} \to \R \, (j = 1,2, \dots, m)$ campos escalares tales que $F(x) = \left( f_1(x), f_2(x), \dots, f_m(x) \right) \, \forall x \in A$\footnote{Los campos escalares $f_j$ quedan determinados un�vocamente por $F$ de la siguiente manera: 
 \begin{align*}
     f_j &: A \subset \Rn{n} \to \R \\
     &f_j(x) = F(x) \cdot e_j,
 \end{align*} donde $e_j$ es el $j$-�simo vector can�nico de $\Rn{m}$.}.\\
 Sea $L = \left( L_1, L_2, \dots, L_m \right) \in \Rn{m}$, $L_j \in \R \, \forall j = 1,2, \dots, m$. Entonces:
 \[
  \lim_{x \to x_o} F(x) = L \iff \lim_{x \to x_o} f_j(x) = L_j \, \forall j = 1,2, \dots, m.
 \]

\end{propiedad}


  \begin{propiedad} \label{prop:lim_1}
    Sean $f:A \subset \Rn{n} \to \R$ una funci�n y $x_0$ un punto de acumulaci�n de $A$. Las siguientes proposiciones son equivalentes:
 \begin{enumerate} [i.]
  \item $\lim_{x \to x_o} f(x) = 0$.
  \item $\lim_{x \to x_o} \abs{ f(x) } = 0$.
 \end{enumerate}
 \begin{proof}
 \mbox{}
 
 \begin{enumerate} [(a)]
  \item Veamos que (I) implica (II). Como 
  \[
   \lim_{x \to x_o} f(x) = 0,
  \]
  por definici�n de l�mite, dado $\varepsilon > 0$ podemos tomar $\delta > 0$ tal que 
  \[
   \abs{f(x) - 0} < \varepsilon \, \forall x \in B^*_{\delta}(x_o) \cap A.
  \]
  Para este valor de $\delta$ se cumple que
  \[
   \Big| \abs{f(x)} - 0 \Big| = \Big| \abs{f(x)} \Big| = \abs{f(x)} = \abs{f(x) - 0} < \varepsilon \, 
   \forall x \in B^*_{\delta}(x_o) \cap A,
  \]
  de modo que, por definici�n, 
  \[
   \lim_{x \to x_o} \abs{ f(x) } = 0.
  \]
  \item Veamos que (II) implica (I). Como
  \[
   \lim_{x \to x_o} \abs{ f(x) } = 0,
  \]
  por definici�n de l�mite, dado $\varepsilon > 0$ podemos tomar $\delta > 0$ tal que 
  \[
   \Big| \abs{f(x)} - 0 \Big| < \varepsilon \, \forall x \in B^*_{\delta}(x_o) \cap A.
  \]
  Para este valor de $\delta$ se cumple que
  \[
   \abs{f(x) - 0} = \abs{f(x)} = \Big| \abs{f(x)} \Big| = \Big| \abs{f(x)} - 0 \Big| < \varepsilon \, 
   \forall x \in B^*_{\delta}(x_o) \cap A,
  \]
  de modo que, por definici�n, 
  \[
   \lim_{x \to x_o} f(x) = 0.
  \]
 \end{enumerate}

  
 \end{proof}

\end{propiedad} 

\begin{propiedad} \label{prop:sandwich} %[Principio de intercalaci�n]
Sean $f, g, h : A \subset \Rn{n} \to \R$ funciones y $x_0$ un punto de acumulaci�n de $A$. Supongamos que $\exists \delta_o > 0$ tal que 
\[
 f(x) \le g(x) \le h(x) \, \forall x \in B_{\delta_o}(x_o) \cap A.
\]
Si $\lim_{x \to x_o}f(x) = \lim_{x \to x_o}h(x) = L$, entonces
\[
 \lim_{x \to x_o}g(x) = L.
\]
 
\end{propiedad}

\begin{propiedad} \label{prop:cero_x_acotada}
 Sean $f, g : A \subset \Rn{n} \to \R$ funciones y $x_0$ un punto de acumulaci�n de $A$. Si $\exists \delta_o > 0$ tal que $f$ es acotada en $B_{\delta_o}(x_o) \cap A$ (i.e.: $\exists M > 0 \text{ tal que } \abs{f(x)} \le M \forall x \in  B_{\delta_o}(x_o) \cap A$) y $\lim_{x \to x_o}g(x) = 0$, entonces
\[
 \lim_{x \to x_o}(f \cdot g)_{(x)} = 0.
\]
\begin{proof}
\mbox{}

Supongamos que, para cierto $\delta_o > 0$, $f$ es acotada en $B_{\delta_o}(x_o) \cap A$, y sea $M > 0 \text{ tal que } \abs{f(x)} \le M \quad \forall x \in  B_{\delta_o}(x_o) \cap A$.
Como 
\[
\lim_{x \to x_o}g(x) = 0, 
\]
dado $\varepsilon > 0 $, por definici�n de l�mite, podemos elegir $\delta_1 > 0$ tal que 
\[
 \abs{g(x)} < \frac{\varepsilon}{M} \quad \forall x \in  B^*_{\delta_1}(x_o) \cap A.                                                                                               
\]
Sea $\delta = \min{ \left\{ \delta_o, \delta_1 \right\} }$. \\
Se cumple que
\[
 \abs{ (f \cdot g)_{(x)} - 0 } = \abs{ f(x) \cdot g(x) } = \abs{f(x)}\abs{g(x)} \le 
 M \abs{g(x)} < M \frac{\varepsilon}{M} = \varepsilon \quad \forall x \in  B^*_{\delta}(x_o) \cap A,
\]
Por lo tanto, por definici�n de l�mite,
\[
 \lim_{x \to x_o}(f \cdot g)_{(x)} = 0.
\]

\end{proof}
\end{propiedad}


\begin{propiedad} [L�mite de la composici�n] \label{prop:lim_comp}
\mbox{}

Sean $f, g$ funciones 
\begin{align*}
 g &:A \subset \Rn{n} \to B \subset \Rn{m} \\
 f &:B \subset \Rn{m} \to \Rn{p},
\end{align*}
y puntos $a \in A', b \in B'$ tales que 
\[
 \lim_{x \to a} g(x) = b \quad \wedge \quad \lim_{u \to b} f(u) = L.
\]
Entonces
\[
 \lim_{x \to a} \left( f \circ g \right)_{(x)} = L.
\]
\end{propiedad}
\begin{exmp}
 Veamos que 
 \[
  \lim_{(x,y) \to (0,0)} \frac{\sin(x^2 + y^2)}{x^2 + y^2} = 1.
 \]
 En efecto, sabemos que 
  \[
    \lim_{u \to 0} \frac{\sin(u)}{u} = 1,
  \]
  y que
  \[
    \lim_{(x,y) \to (0,0)} x^2 + y^2 = 0.
  \]  
  Por lo tanto, si definimos 
  \begin{align*}
   f&: \R - \{0\} \to \R \\
    &f(u) = \frac{\sin(u)}{u} \\
   g&: \Rn{2} - \{(0,0)\} \to \R \\
    &g(x,y) = x^2 + y^2,
  \end{align*}
  por la propiedad \eqref{prop:lim_comp} es
  \[
   \lim_{(x,y) \to (0,0)} \left( f \circ g \right)_{(x,y)} = 
   \lim_{(x,y) \to (0,0)} \frac{\sin(x^2 + y^2)}{x^2 + y^2} = 1.
  \]
\end{exmp}

Una consecuencia directa de la propiedad \eqref{prop:lim_comp} es el siguiente corolario: 
\begin{corolario} [L�mites por curvas] \label{cor:lim_curva}
  Sean $f: A \subset \Rn{2} \to \R, \, (x_o,y_o)$ un punto de acumulaci�n de $A$ y $L \in \R$ tales que 
  \[
   \lim_{(x,y) \to (x_o,y_o)} f(x,y) = L.
  \]

  Entonces, para cualesquiera funciones continuas $g_1, \, g_2 : I \subset \R \to \R$ tales que, para alg�n $t_o \in I'$
  \[
    \lim_{t \to t_o} \left( g_1(t),g_2(t) \right) = \left( x_o , y_o \right)
  \]
  y, adem�s, $\left( g_1(t), g_2(t) \right) \in A \, \forall t \in \left( I - \{t_o\} \right),$ se cumple que
  
  \[
   \lim_{t \to t_o} f\left( g_1(t),g_2(t) \right) = L.
  \]
\end{corolario}
\begin{exmp}
 \begin{align*}
   f: &\left\lbrace (x,y) \in \Rn{2} : x \ne y \right\rbrace \to \R \\
   &f(x,y) = \frac{x^2}{x - y}.
  \end{align*} 
  Veamos que $f$ no tiene l�mite para $(x,y) \to (0,0)$.
  \begin{enumerate} [(a)]
   \item  Sean $g_1(t) = t, \, g_2(t) = t + t^2$.
  \[
   f(g_1(t),g_2(t)) = f(t,t + t^2) = \frac{t^2}{-t^2} \to -1 \text{ cuando } t \to 0,
  \]
  de modo que, \emph{si $f$ tiene l�mite}, el l�mite es -1, por \eqref{cor:lim_curva} y la unicidad del l�mite.
  \item  Sean $g_1(t) = t, \, g_2(t) = t - t^2$.
  \[
   f(g_1(t),g_2(t)) = f(t,t + t^2) = \frac{t^2}{t^2} \to 1 \text{ cuando } t \to 0,
  \]
  de modo que, \emph{si $f$ tiene l�mite}, el l�mite es 1, por \eqref{cor:lim_curva} y la unicidad del l�mite.
  \end{enumerate}
  Por lo tanto, por la unicidad del l�mite (teorema \eqref{teo:unicidad_limite}), \emph{si $f$ tiene l�mite $L$}, $L = 1 = -1$, lo que es un absurdo. El absurdo provino de suponer que $f$ tiene l�mite, por lo cual $f$ no puede tener l�mite.
\end{exmp}

\begin{propiedad}[L�mites iterados] \label{prop:lim_ite}
  Sean $f: A \subset \Rn{2} \to \R$, $(x_o,y_o)$ un punto de acumulaci�n de $A$ y $L \in \R$ tales que
  \[
   \lim_{(x,y) \to (x_o,y_o)} f(x,y) = L.
  \]
  \begin{enumerate} [I.]
   \item Si para cada $x \ne x_o$ existe el l�mite
  \[
   \lim_{y \to y_o} f(x,y) = g(x)
  \]
  y adem�s existe el l�mite
  \[
   \lim_{x \to x_o} g(x) = \lim_{x \to x_o} \left( \lim_{y \to y_o} f(x,y) \right) = L_1,
  \]  
  entonces $L = L1$.
  \item Si para cada $y \ne y_o$ existe el l�mite
  \[
   \lim_{x \to x_o} f(x,y) = h(y)
  \]
  y adem�s existe el l�mite
  \[
   \lim_{y \to y_o} h(y) = \lim_{y \to y_o} \left( \lim_{x \to x_o} f(x,y) \right) = L_2, 
  \]
  entonces $L = L_2$.
  \end{enumerate}
\end{propiedad}
% \emph{Ejemplos:
% \begin{itemize}
%  \item existan los iterados, sean distintos
%  \item existan los iterados, sean iguales, pero no hay l�mite
%  \item existan los iterados, sean iguales, probar por def que existe el l�mite
%  \item ejemplo en el que exista el l�mite doble pero no los iterados
% \end{itemize}
% }

\begin{propiedad}[L�mites por conjuntos] \label{prop:lim_x_conj}
   Sea $f : A \subset \Rn{n} \to \Rn{m}$ una funci�n, con $A = A_1 \cup A_2$.\\
   Sea $f_1$ la \emph{restricci�n de $f$ a $A_1$}:
 \begin{align*}
  f_1 &: A_1 \subset \Rn{n} \to \Rn{m} \\
  &f_1(x) = f(x).
 \end{align*}
Sea $f_2$ la \emph{restricci�n de $f$ a $A_2$}:
 \begin{align*}
  f_2 &: A_2 \subset \Rn{n} \to \Rn{m} \\
  &f_2(x) = f(x).
 \end{align*}
 Sean $x_o \in A_1' \cap A_2'$ y $L \in \Rn{m}$. Entonces
 \[
  \lim_{x \to x_o} f(x) = L \quad \iff 
  \lim_{x \to x_o} f_1(x) = L \wedge \lim_{x \to x_o} f_2(x) = L.
 \]
\end{propiedad}
\begin{exmp}
\mbox{}

 Sea 
  \[
   f(x,y) = 
     \begin{cases}
        \frac{e^x - 1}{x}  & \text{ si } x \ne 0  \\
         1                 & \text{ si } x = 0
     \end{cases}
  \]
 Veamos que $\lim_{(x,y) \to (0,0)} f(x,y) = 1$.\\
 Sean $A_1 = \{ (x,y) \in \Rn{2} : x \ne 0\}, \, A_2 = \{ (x,y) \in \Rn{2} : x = 0\}$ y 
 \begin{align*}
  f_1 &: A_1 \to \R \\
  &f_1(x,y) = \frac{e^x - 1}{x}, \\
  f_2 &: A_2 \to \R \\
  &f_2(x,y) = 1.
  \end{align*}
 Como 
 \[
    \lim_{t \to 0} \frac{e^t - 1}{t} = 1
 \]
 y 
 \[
    \lim_{(x,y) \to (0,0)} x = 0,
 \]
 por la propiedad \eqref{prop:lim_comp} es 
 \[
    \lim_{(x,y) \to (0,0)} f_1(x,y) = 1.
 \]
Como adem�s $\lim_{(x,y) \to (0,0)} f_2(x,y) = 1$ y $A_1 \cup A_2 = \Rn{2}$, por la propiedad \eqref{prop:lim_x_conj} es
 \[
  \lim_{(x,y) \to (0,0)} f(x,y) = 1.
 \]
\end{exmp}

\begin{definition}\textbf{L�mite infinito.} \label{def:lim_inf}
  Sean $f : A \subset \Rn{n} \to \R$ una funci�n y $x_0$ un punto de acumulaci�n de $A$. 
  \begin{enumerate} [I.]
   \item Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $+\infty$} o que \emph{$f$ tiende a $+\infty$ cuando $x$ tiende a $x_o$} si
    \[
      \forall M > 0 \, \exists \delta > 0 / f(x) > M \, \forall 
	  x \in B_{\delta}^*(x_o) \cap A.
    \]
    En este caso, utilizamos la notaci�n
    \[
      f(x) \xrightarrow[x \to x_o]{} +\infty \quad \text{o} \quad \lim_{x \to x_o} f(x) = +\infty.
    \]
   \item Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $-\infty$} o que \emph{$f$ tiende a $-\infty$ cuando $x$ tiende a $x_o$} si
    \[
      \forall M > 0 \, \exists \delta > 0 / f(x) < -M \, \forall 
	  x \in B_{\delta}^*(x_o) \cap A.
    \]
    En este caso, utilizamos la notaci�n
    \[
      f(x) \xrightarrow[x \to x_o]{} -\infty \quad \text{o} \quad \lim_{x \to x_o} f(x) = -\infty.
    \]
   \item Decimos que \emph{el l�mite de $f$ para $x$ tendiendo a $x_o$ es $\infty$} o que \emph{$f$ tiende a $\infty$ cuando $x$ tiende a $x_o$} si
    \[
      \forall M > 0 \, \exists \delta > 0 / \abs{f(x)} > M \, \forall 
	  x \in B_{\delta}^*(x_o) \cap A.
    \]
    En este caso, utilizamos la notaci�n
    \[
      f(x) \xrightarrow[x \to x_o]{} \infty \quad \text{o} \quad \lim_{x \to x_o} f(x) = \infty.
    \]
  \end{enumerate}
\end{definition}

\begin{definition}\textbf{L�mite en el infinito.} \label{def:lim_x_inf}
Sean $f : \Rn{n} \to \R$ una funci�n y $L \in \R$. Decimos que
%la manera de presentar esta definici�n no es consistente con las anteriores
\[
 f(x) \xrightarrow[\norm{x} \to +\infty]{} L \quad \text{o} \quad \lim_{\norm{x} \to +\infty} f(x) = L
\]
si 
\[ 
 \forall \varepsilon > 0 \, \exists \delta > 0 / f(x) \in B_{\varepsilon}(L) \, \forall 
 x / \norm{x} > \delta.
\]
\end{definition}


\iffalse
\begin{propiedad} \label{prop:lim_2}
 Sean $f:A \subset \Rn{m} \to \Rn{m}$, $g:A \to \R$ y $x_0$ un punto de acumulaci�n de $A$, tales que 
 \[
  \lim_{x \to x_o} g(x) = L_g \quad \wedge \quad \lim_{x \to x_o} \left( (f + g)_{(x)} \right) = L.
 \]
 Entonces, existe el l�mite $\lim_{x \to x_o} f(x)$ y, adem�s, $\lim_{x \to x_o} f(x) = L - L_g$.
\end{propiedad}
\fi

\section{Diferenciabilidad.} \label{sec:diferenciabilidad}

\begin{definition}\textbf{Diferenciabilidad de campos escalares.} \label{def:dif_escalar}
\mbox{}
Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$. Decimos que $f$ es \emph{diferenciable en $x_o$} si $\exists m \in \Rn{n}$ tal que
\[
  \lim_{x \to x_o} \frac{f(x) - f(x_o) - m \cdot (x - x_o)}{\norm{x - x_o}} = 0.
\]
Si $A$ es un conjunto abierto, decimos que $f$ es \emph{diferenciable} si es diferenciable en cada punto $x_o \in A$.
\end{definition}

\begin{definition}\textbf{Diferenciabilidad, caso general.} \label{def:dif_general}
\mbox{}

Sean $f: A \subset \Rn{n} \to \Rn{m}$ y $x_o \in \interior{(A)}$. Decimos que $f$ es \emph{diferenciable en $x_o$} si $\exists M \in \Rnp{m}{n}$ tal que
\[
  \lim_{x \to x_o} \frac{\norm{f(x) - f(x_o) - M \cdot (x - x_o)}}{\norm{x - x_o}} = 0.
\]
Si $A$ es un conjunto abierto, decimos que $f$ es \emph{diferenciable} si es diferenciable en cada punto $x_o \in A$.
\end{definition}

\begin{theorem}\textbf{Diferenciabilidad y continuidad.} \label{teo:difCont}
\mbox{}

Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$. Si $f$ es diferenciable en $x_o$, entonces $f$ es continua en $x_o$.
 \begin{proof}
 \mbox{}
 
 Como $f$ es diferenciable en $x_o, \exists m \in \Rn{n}$ tal que
 \[
  \lim_{x \to x_o} \frac{f(x) - f(x_o) - m \cdot (x - x_o)}{\norm{x - x_o}} = 0.
 \]
Por lo tanto, $\exists \delta_o > 0$ tal que 
\[
 x \in B_{\delta_o}^* \cap A \then 
 \abs{ \frac{f(x) - f(x_o) - m \cdot (x - x_o)}{\norm{x - x_o}} } < 1.
\]
Entonces, para este $\delta_o$, se cumple que
\[
 \abs{ f(x) - f(x_o) - m \cdot (x - x_o) } < \norm{x - x_o}, \, \forall x \in B_{\delta_o}^* \cap A.
\]
% Como ambos miembros de esta desigualdad (estricta) son iguales cuando $x = x_o$, vale que
% \[
%  \abs{ f(x) - f(x_o) - m \cdot (x - x_o) } \le \norm{x - x_o}, \, \forall x \in B_{\delta_o} \cap A.
% \]
Por lo tanto,
\begin{align*}
\abs{ f(x) - f(x_o) } &=   \abs{ f(x) - f(x_o) - m \cdot (x - x_o) + m \cdot (x - x_o) } \le \\
                      &\le \abs{ f(x) - f(x_o) - m \cdot (x - x_o) } + \abs{ m \cdot (x - x_o) } < \\
                      &< \norm{x - x_o} + \abs{ m \cdot (x - x_o) }, \, 
                      \forall x \in B^*_{\delta_o} \cap A.
\end{align*}
Por la desigualdad de Cauchy-Schwarz, $\abs{ m \cdot (x - x_o) } \le \norm{m} \norm{x - x_o}$, y entonces:
\begin{align*}
\abs{ f(x) - f(x_o) } &< \norm{x - x_o} + \abs{ m \cdot (x - x_o) } \le \\
                      &\le \norm{x - x_o} + \norm{m} \norm{x - x_o} = \\
                      &=  \left( 1 + \norm{m} \right) \norm{x - x_o}, \, 
                      \forall x \in B^*_{\delta_o} \cap A.
\end{align*}
Esta condici�n garantiza la continuidad de $f$ en $x_o$. En efecto, dado $\epsilon > 0$, sea $\delta = \min \{\delta_o, \frac{\epsilon}{1 + \norm{m}} \}$. Para este $\delta$ se cumple que:
\begin{align*}
 \abs{ f(x) - f(x_o) } &< \left( 1 + \norm{m} \right) \norm{x - x_o} < \\
                       &<   \left( 1 + \norm{m} \right) \delta \le \\
                       &\le \left( 1 + \norm{m} \right) \frac{\epsilon}{1 + \norm{m}} = \epsilon, 
                       \, \forall x \in B^*_{\delta} \cap A,
\end{align*}
lo que, por definici�n de l�mite \footnote{Como $x_o \in \interior{(A)}$, $x_o$ es un punto de acumulaci�n de $A$. }, significa que 
\[
 \lim_{x \to x_o}f(x) = f(x_o).
\]
Es decir, $f$ es continua en $x_o$.
\end{proof}
\begin{obs} La implicaci�n rec�proca de la proposici�n \eqref{teo:difCont} es falsa. 
 \begin{proof} La funci�n
  \begin{align*}
      g & :\R \to \R \\
        & g(t) = \abs{t}
 \end{align*}
es continua en $t_o = 0$, pero no es diferenciable en $t_o = 0$. Se deja como ejercicio para el lector verificar esta afirmaci�n.
 \end{proof}
\end{obs}
\end{theorem}

\begin{theorem}\textbf{Diferenciabilidad y existencia de derivadas parciales.} \label{teo:difDer}
\mbox{}

\iffalse
Sean $f: A \subset \Rn{2} \to \R$ y $(x_o, y_o) \in \interior{(A)}$, tales que $\exists \alpha, \beta \in \R \, /$
\[
 \lim_{(x,y) \to (x_o,y_o)} \frac{f(x,y) - f(x_o,y_o) - \alpha(x - x_o) - \beta(y - y_o)}
                                 {\norm{(x - x_o, y - y_o)}} = 0
\]
(es decir, $f$ es diferenciable en $(x_o,y_o)$). Entonces existen las derivadas parciales de $f$ en $(x_o,y_o)$ y, adem�s,
\[
 \dif{f}{x} (x_o,y_o) = \alpha, \quad \dif{f}{y}(x_o,y_o) = \beta.
\]

 \begin{proof}
 \mbox{}
 
Sea $(x,y) = (x_o,y_o) + h e_1$, siendo $h \in \R$ y $e_1$ el primer vector can�nico ($e_1 = (1,0)$). Es decir, definimos una funci�n $g:(-\delta,\delta) \to \Rn{2} / g(h) = (x_o,y_o) + h e_1$, con $\delta > 0$, lo suficientemente peque�o como para que $\im(g) \subset A$ \footnote{�Cu�l de las hip�teis asegura la existencia de un tal $\delta$?}, y llamamos $(x,y) = g(h)$. Notemos que $g(h) \to (x_o,y_o)$ cuando $h \to 0$. 

Por la diferenciabilidad, tenemos que 
\[
 \lim_{(x,y) \to (x_o,y_o)} \frac{f(x,y) - f(x_o,y_o) - \alpha(x - x_o) - \beta(y - y_o)}
                                 {\norm{(x - x_o, y - y_o)}} = 0
\]
y entonces, si componemos con la funci�n $g$ (reemplazamos $(x,y) = (x_o,y_o) + h e_1$), la propiedad del l�mite de la composici�n \eqref{prop:lim_comp} implica que
\begin{align*}
  0 & = \lim_{h \to 0} \frac{f(x_o + h,y_o) - f(x_o,y_o) - \alpha(x_o + h - x_o) - \beta(y_o - y_o)}
                                 {\norm{(x_o + h - x_o, y_o - y_o)}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h,y_o) - f(x_o,y_o) - \alpha h}{\norm{h e_1}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h,y_o) - f(x_o,y_o) - \alpha h}{\abs{h}} .
\end{align*}                                
Ahora bien, este l�mite es $0$ si y solo si
\[
 \lim_{h \to 0} \abs{ \frac{f(x_o + h,y_o) - f(x_o,y_o) - \alpha h}{\abs{h}} } = 0,
\]
por la propiedad \eqref{prop:lim_1}. Entonces,
\begin{align*}
  0 & =  \lim_{h \to 0} \abs{ \frac{f(x_o + h,y_o) - f(x_o,y_o) - \alpha h}{\abs{h}} }
      = \lim_{h \to 0} \frac{ \abs{ f(x_o + h,y_o) - f(x_o,y_o) - \alpha h }}{\abs{ \, \abs{h} \, }} = \\
    & = \lim_{h \to 0} \frac{ \abs{ f(x_o + h,y_o) - f(x_o,y_o) - \alpha h }}{\abs{h}}
      = \lim_{h \to 0} \abs{ \frac{ f(x_o + h,y_o) - f(x_o,y_o) - \alpha h }{h}},
\end{align*} 
lo cual, otra vez por la propiedad \eqref{prop:lim_1}, implica que 
\[
 0 = \lim_{h \to 0} \frac{ f(x_o + h,y_o) - f(x_o,y_o) - \alpha h }{h} =
     \lim_{h \to 0} \left( \frac{ f(x_o + h,y_o) - f(x_o,y_o) }{h} - \alpha \right) .
\]
\fi

\iffalse
Entonces, por la propiedad \eqref{prop:lim_2}, tenemos que
\[
 \lim_{h \to 0} \frac{ f(x_o + h,y_o) - f(x_o,y_o) }{h} = \alpha,
\]
\fi
Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$, tales que $\exists m = (m_1, m_2, \cdots, m_n) \in \Rn{n} \, /$
\[
 \lim_{x \to x_o} \frac{f(x) - f(x_o) - m \cdot (x - x_o)}
                                 {\norm{x - x_o}} = 0
\]
(es decir, $f$ es diferenciable en $x_o$). Entonces existen las derivadas parciales de $f$ en $x_o$ y, adem�s,
\[
 \dif{f}{x_j} (x_o) = m_j \quad \forall j = 1, 2, \cdots, n.
\]

 \begin{proof}
 \mbox{}
 
Sea $x = x_o + h e_j$, siendo $h \in \R$ y $e_j$ el $j$-�simo vector can�nico (el vector de $\Rn{n}$ que tiene un $1$ en la posici�n $j$ y ceros en todas las dem�s). Es decir, definimos una funci�n $g:(-\delta,\delta) \to \Rn{n} / g(h) = x_o + h e_j$, con $\delta > 0$, lo suficientemente peque�o como para que $\im(g) \subset A$ \footnote{�Cu�l de las hip�teis asegura la existencia de un tal $\delta$?}, y llamamos $x = g(h)$. Notemos que $g(h) \to x_o$ cuando $h \to 0$. 

Por la diferenciabilidad, tenemos que 
\[
 \lim_{x \to x_o} \frac{f(x) - f(x_o) - m \cdot (x - x_o)}
                                 {\norm{x - x_o}} = 0
\]
y entonces, si componemos con la funci�n $g$ (reemplazamos $x = x_o + h e_j$), la propiedad del l�mite de la composici�n \eqref{prop:lim_comp} implica que
\begin{align*}
  0 & = \lim_{h \to 0} \frac{f(x_o + h e_j) - f(x_o) - m \cdot ((x_o + he_j) - x_o)}
                                 {\norm{(x_o + he_j) - x_o}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h e_j) - f(x_o) - m \cdot (he_j)}{\norm{h e_j}} = \lim_{h \to 0} \frac{f(x_o + h e_j) - f(x_o) - h(m \cdot e_j)}{\norm{h e_j}} =\\
    & = \lim_{h \to 0} \frac{f(x_o + h e_j) - f(x_o) - h m_j}{\abs{h}} .
\end{align*}                                
Ahora bien, este l�mite es $0$ si y solo si
\[
 \lim_{h \to 0} \abs{ \frac{f(x_o + h e_j) - f(x_o) - h m_j}{\abs{h}} } = 0,
\]
por la propiedad \eqref{prop:lim_1}. Entonces,
\begin{align*}
  0 & = \lim_{h \to 0} \abs{ \frac{f(x_o + h e_j) - f(x_o) - h m_j}{\abs{h}} }
      = \lim_{h \to 0} \frac{\abs{f(x_o + h e_j) - f(x_o) - h m_j}}{\abs{\abs{h}}} = \\
    & = \lim_{h \to 0} \frac{\abs{f(x_o + h e_j) - f(x_o) - h m_j}}{\abs{h}}
      = \lim_{h \to 0} \abs{ \frac{f(x_o + h e_j) - f(x_o) - h m_j}{h} },
\end{align*} 
lo cual, otra vez por la propiedad \eqref{prop:lim_1}, implica que 
\[
 0 = \lim_{h \to 0} \frac{f(x_o + h e_j) - f(x_o) - h m_j}{h} =
     \lim_{h \to 0} \left( \frac{f(x_o + h e_j) - f(x_o)}{h} - m_j \right) .
\]

Es f�cil probar por definici�n que esta �ltima condici�n implica que
\[
 \lim_{h \to 0} \frac{ f(x_o + h e_j) - f(x_o) }{h} = m_j.
\]
En efecto, dado $\epsilon > 0$ existe $\delta > 0$ tal que 
\[
 \abs{ \left( \frac{ f(x_o + h e_j) - f(x_o) }{h} - m_j \right) - 0 } < \epsilon, \, \forall h : 0 < \abs{h} < \delta,
\]
porque el l�mite es 0. Como claramente 
\[
 \abs{ \left( \frac{ f(x_o + h e_j) - f(x_o) }{h} - m_j \right) - 0 } = 
 \abs{\frac{ f(x_o + h e_j) - f(x_o) }{h} - m_j},
\]
se tiene (por definici�n de l�mite) que 
\[
 \lim_{h \to 0} \frac{ f(x_o + h e_j) - f(x_o) }{h} = m_j.
\]
Esto �ltimo, por definici�n de derivada parcial, significa que
\[
  \dif{f}{x_j} (x_o) = m_j,
\]
como quer�amos probar. 

 \end{proof}

\begin{obs}
 Es un error decir, en el �ltimo paso de la demostraci�n, que por la linealidad del l�mite
 \[
  \lim_{h \to 0} \left( \frac{f(x_o + h e_j) - f(x_o)}{h} - m_j \right) = 
  \lim_{h \to 0} \left( \frac{f(x_o + h e_j) - f(x_o)}{h} \right) - \lim_{h \to 0} m_j = 0,
 \]
ya que la existencia del l�mite 
\[
\lim_{h \to 0} \left( \frac{f(x_o + h e_j) - f(x_o)}{h} \right)
\]
es parte de lo que debemos probar.
\end{obs}
\begin{obs} La implicaci�n rec�proca de la proposici�n \eqref{teo:difDer} es falsa.
\begin{proof}
\mbox{}
  
La funci�n
 \[
       f :\Rn{2} \to \R
      \]
      \[
        f(x,y) = 
        \begin{cases}
         0 & \text{ si } x y = 0  \\
         1 & \text{ en otro caso }
        \end{cases}
\]
tiene derivadas parciales en el origen, pero no es diferenciable en el origen.\\
Se deja como ejercicio para el lector la demostraci�n de esta afirmaci�n.
\end{proof}
\end{obs}
\end{theorem}

Una consecuencia directa del teorema \eqref{teo:difDer} es el siguiente corolario:
\begin{corolario}
 Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$. Son equivalentes:
 \begin{enumerate} [I.]
  \item $f$ es diferenciable en $x_o$;
  \item existen todas las derivadas parciales de $f$ en $x_o$ y 
  \[
   \lim_{x \to x_o} \frac{f(x) - f(x_o) - \grad f (x_o) \cdot (x - x_o)}{\norm{x - x_o}} = 0.
  \]
 \end{enumerate}
\end{corolario}

\begin{theorem}\textbf{Diferenciabilidad y existencia de derivadas direccionales.}\label{teo:difDir}
% La idea es incluir tres demostraciones, una usando la misma idea que para la demo de las derivadas parciales, otra usando que el delta f se puede escribir de una determinada manera y construyendo el cociente incremental, una tercera utilizando la regla de la cadena
\mbox{}

Sea $f: A \subset \Rn{n} \to \R$ diferenciable en $x_o \in \interior{(A)}$. Entonces, $\forall \check{u} \in \Rn{n} \text{tal que } \norm{\check{u}} = 1$ existe en $x_o$ la derivada de $f$ en la direcci�n de $\check{u}$ y, adem�s,
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = \grad f (x_o) \cdot \check{u}.
\]

 \begin{proof}
 \mbox{}
 
 Sea $x = x_o + h \check{u}$, siendo $h \in \R$. Es decir, definimos una funci�n 
 \begin{align*}
      g & :(-\delta,\delta) \to \Rn{n} \\
        & g(h) = x_o + h \check{u}
 \end{align*}

con $\delta > 0$, lo suficientemente peque�o como para que $\im(g) \subset A$, y llamamos $x = g(h)$. Notemos que $g(h) \to x_o$ cuando $h \to 0$. 

Por la diferenciabilidad, tenemos que 
\[
 \lim_{x \to x_o} \frac{f(x) - f(x_o) - \grad f (x_o) \cdot (x - x_o)}
                                 {\norm{x - x_o}} = 0
\]
y entonces, si componemos con la funci�n $g$ (reemplazamos $x = x_o + h \check{u}$), la propiedad del l�mite de la composici�n \eqref{prop:lim_comp} implica que
\begin{align*}
  0 & = \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o) - \grad f (x_o) \cdot ((x_o + h _{\delta}(x_o)\check{u}) - x_o) }
                    {\norm{(x_o + h \check{u}) - x_o}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o) - \grad f (x_o) \cdot (h \check{u}) }
                    {\norm{h \check{u}}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o) - h \grad f (x_o) \cdot \check{u} }
                    {\abs{h} \norm{\check{u}}} = \\
    & = \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o) - h \grad f (x_o) \cdot \check{u} }
                    {\abs{h}}.  
\end{align*}                                
Como en la demostraci�n de la propiedad \eqref{teo:difDer}, este l�mite es $0$ si y solo si
\[
 0 = \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o) - h \grad f (x_o) \cdot \check{u}}{h} = 
     \lim_{h \to 0} \left( \frac{f(x_o + h \check{u}) - f(x_o)}{h} - \grad f (x_o) \cdot \check{u} \right),
\]
que, como en la demostraci�n de \eqref{teo:difDer}, implica que 
\[
 \lim_{h \to 0} \frac{f(x_o + h \check{u}) - f(x_o)}{h} = \grad f (x_o) \cdot \check{u}
\]
y por lo tanto, por definici�n,
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = \grad f (x_o) \cdot \check{u}.
\]
 \end{proof}
\end{theorem}

\begin{theorem}\textbf{Valores extremos de la derivada direccional.} \label{teo:max_deriv}
\mbox{}

 Sean $f: A \subset \Rn{n} \to \R$ diferenciable en un punto $x_o \in \interior{(A)}$. Entonces 
 \[
  \max_{\norm{\check{u}} = 1} \frac{\partial f}{\partial \check{u}} (x_o) = \norm{\grad f (x_o)}, \quad 
  \min_{\norm{\check{u}} = 1} \frac{\partial f}{\partial \check{u}} (x_o) = -\norm{\grad f (x_o)}
 \]
y, si $\grad f(x_o) \ne \mathbf{0}$,
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = \norm{\grad f (x_o)} \iff \check{u} = \frac{\grad f(x_o)}{\norm{\grad f(x_o)}}
\]
y
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = -\norm{\grad f (x_o)} \iff \check{u} = -\frac{\grad f(x_o)}{\norm{\grad f(x_o)}}.
\]
\begin{proof}
\mbox{}

 Como $f$ es diferenciable en $x_o$, por el teorema \eqref{teo:difDir}, $\forall \check{u} \in \Rn{n} \text{tal que } \norm{\check{u}} = 1$ existe en $x_o$ la derivada de $f$ en la direcci�n de $\check{u}$ y, adem�s,
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = \grad f (x_o) \cdot \check{u}.
\]
Por la desigualdad de Cauchy-Schwarz, 
\[
 \abs{\frac{\partial f}{\partial \check{u}} (x_o)} = \abs{\grad f (x_o) \cdot \check{u}} \le \norm{\grad f (x_o)}\norm{\check{u}} = \norm{\grad f (x_o)},
\]
de modo que tenemos las cotas:
\[
 -\norm{\grad f (x_o)} \le \frac{\partial f}{\partial \check{u} (x_o)} \le \norm{\grad f (x_o)}.
\]
Adem�s, la desigualdad de Cauchy-Schwarz nos dice que vale
\[
 \abs{\frac{\partial f}{\partial \check{u}} (x_o)} = \norm{\grad f (x_o)}
\]
si y solo si el conjunto $\{\grad f(x_o), \check{u} \}$ es linealmente dependiente, condici�n que, si $\grad f(x_o) \ne \mathbf{0}$, es equivalente a decir que $\check{u}$ es un vector unitario en la direcci�n de $\grad f(x_o)$. Existen exactamente dos vectores $\check{u}$ con esta caracter�stica:
\[
 \check{u}_1 = \frac{\grad f(x_o)}{\norm{\grad f(x_o)}} \quad \text{ y } \quad \check{u}_2 = -\frac{\grad f(x_o)}{\norm{\grad f(x_o)}}.
\]
Por c�lculo directo:
\begin{align*}
 \frac{\partial f}{\partial \check{u}_1} (x_o) &= \grad f (x_o) \cdot \frac{\grad f(x_o)}{\norm{\grad f(x_o)}} = \frac{ \grad f (x_o) \cdot \grad f(x_o) }{\norm{\grad f(x_o)}} = \frac{\norm{\grad f (x_o)}^2 }{\norm{\grad f(x_o)}} = \norm{\grad f (x_o)} \\
%  
 \frac{\partial f}{\partial \check{u}_2} (x_o) &= \grad f (x_o) \cdot \left( - \frac{\grad f(x_o)}{\norm{\grad f(x_o)}} \right) = -\frac{ \grad f (x_o) \cdot \grad f(x_o) }{\norm{\grad f(x_o)}} = -\frac{\norm{\grad f (x_o)}^2 }{\norm{\grad f(x_o)}} = -\norm{\grad f (x_o)},
\end{align*}
de modo que efectivamente
\[
 \max_{\norm{\check{u}}=1} \frac{\partial f}{\partial \check{u}} (x_o) = \norm{\grad f (x_o)}
\]
y el m�ximo se realiza en $\check{u}_1 = \frac{\grad f(x_o)}{\norm{\grad f(x_o)}}$,
y
\[
 \min_{\norm{\check{u}}=1} \frac{\partial f}{\partial \check{u}} (x_o) = -\norm{\grad f (x_o)}
\]
y el m�nimo se realiza en $\check{u}_2 = -\frac{\grad f(x_o)}{\norm{\grad f(x_o)}}$. \\

Finalmente, observemos que, si $\grad f(x_o) = \mathbf{0}$, 
\[
 \frac{\partial f}{\partial \check{u}} (x_o) = \grad f (x_o) \cdot \check{u} = 0 = \norm{\grad f(x_o)} \quad \forall \check{u} \in \Rn{n},
\]
y por lo tanto:
\[
 \max_{\norm{\check{u}}=1} \frac{\partial f}{\partial \check{u}} (x_o) = \norm{\grad f(x_o)} = 0
\]
y
\[
 \min_{\norm{\check{u}}=1} \frac{\partial f}{\partial \check{u}} (x_o) = -\norm{\grad f(x_o)} = 0.
\]

\end{proof}

\end{theorem}

\begin{theorem}\textbf{Regla de la cadena.} \label{teo:cadena}
\mbox{}

  Sean $f, g$ funciones 
    \begin{align*}
    g &:A \subset \Rn{n} \to B \subset \Rn{m} \\
    f &:B \subset \Rn{m} \to \Rn{p},
    \end{align*}
  y un punto $x_o \in \interior{A} \text{ tal que } g(x_o) \in \interior{B}$. Supongamos que $g$ es diferenciable en $x_o$ y que $f$ es diferenciable en $yo = g(x_o)$. Entonces la composic�n $f \circ g$ es diferenciable en $x_o$ y, adem�s,
  \[
   \boldsymbol{D}(f \circ g)_{(x_o)} = \boldsymbol{D}f_{(y_o)} 
   \boldsymbol{D}g_{(x_o)}.
  \]
\end{theorem}

\begin{theorem}\textbf{Teorema de la Funci�n Inversa.} \label{teo:inversa}
\mbox{}

 Sean $A \subset \Rn{n}$ un conjunto abierto y $F: A \subset \Rn{n} \to \Rn{n}$ una funci�n de clase $\mathcal{C}^1$. Sea $x_o \in A$ y supongamos que $\det(\boldsymbol{D}F_{(x_o)}) \ne 0$. Entonces existen un entorno abierto $U \subset A$ de $x_o$ y un entorno abierto $V \subset \Rn{n}$ de $F(x_o)$ tal que $F:U \to V$ (la restricci�n de $F$ a $U$) tiene inversa $F^{-1}:V \to U$. Esta funci�n $F^{-1}$ es de clase $\mathcal{C}^1$ y, adem�s,
 \[
  \boldsymbol{D}F^{-1}_{(F(x_o))} = \left[ \boldsymbol{D}F_{(x_o)} \right]^{-1}.
 \]
 Si $F$ es de clase $\mathcal{C}^p, p \ge 1,$ entonces $F^{-1}$ tambi�n.
\end{theorem}

\begin{theorem}\textbf{Caso particular del Teorema de la Funci�n Impl�cita.} \label{teo:implicit_part}
\mbox{}

Sean $A \subset \Rn{3}$ un conjunto abierto y $F: A \to \R$ una funci�n de clase $\mathcal{C}^1$. Sea $(x_o,y_o,z_o) \in A$ tal que $F(x_o,y_o,z_o) = 0$. Supongamos que 
 \[
   F_z (x_o,y_o,z_o) \ne 0.
 \]
 Entonces existen un entorno abierto $U \subset \Rn{2}$ de $(x_o,y_o)$
 %, un entorno abierto $V \subset \Rn{m}$ de $y_o$ 
 y una �nica funci�n $g: U \to \R$ tales que $g(x_o,y_o) = z_o$ y
 \[
  F(x,y,g(x,y)) = 0 \, \forall (x,y) \in U.
 \]
 M�s a�n, $g$ es de clase $\mathcal{C}^1$ y, adem�s, $\forall (x,y) \in U$ vale que
 \begin{align*}
  g_{x}(x,y) &= -\frac{F_x (x,y,g(x,y))}{F_z (x,y,g(x,y))}  \\
  g_{y}(x,y) &= -\frac{F_y (x,y,g(x,y))}{F_z (x,y,g(x,y))} \\
 \end{align*}
 Si $F$ es de clase $\mathcal{C}^p, p \ge 1,$ entonces $g$ tambi�n.
 
\end{theorem}


\begin{theorem}\textbf{Teorema de la Funci�n Impl�cita.} \label{teo:implicit}
\mbox{}

 Sean $A \subset \Rn{n} \times \Rn{m}$ un conjunto abierto y $F: A \to \Rn{m}$ una funci�n de clase $\mathcal{C}^1$. Sea $(x_o,z_o) \in A$ tal que $F(x_o,z_o) = \mathbf{0}$. Formemos el determinante
 \[
  \Delta = \det \begin{bmatrix*}[r]
                \dif{f_1}{z_1} & \dif{f_1}{z_2} & \cdots & \dif{f_1}{z_m} \\
                               &                &        &                \\
                \dif{f_2}{z_1} & \dif{f_2}{z_2} & \cdots & \dif{f_2}{z_m} \\
                               &                &        &                \\
                \vdots         &                & \ddots & \vdots         \\
                               &                &        &                \\
                \dif{f_m}{z_1} & \dif{f_m}{z_2} & \cdots & \dif{f_m}{z_m}
                \end{bmatrix*},
 \]
 donde $F = (f_1, f_2, \cdots , f_m)$ y todas las derivadas est�n evaluadas en $(x_o,z_o)$. Si $\Delta \ne 0$, entonces existen un entorno abierto $U \subset \Rn{n}$ de $x_o$
 %, un entorno abierto $V \subset \Rn{m}$ de $z_o$ 
 y una �nica funci�n $g: U \to \Rn{m}$ tales que $g(x_o) = z_o$ y
 \[
  F(x,g(x)) = \mathbf{0} \, \forall x \in U.
 \]
 M�s a�n, $g$ es de clase $\mathcal{C}^1$ y, adem�s, si $g = (g_1, g_2, \cdots , g_m)$,
 \[
  \begin{bmatrix*}[r]
                \dif{g_1}{x_1} & \dif{g_1}{x_2} & \cdots & \dif{g_1}{x_n} \\
                               &                &        &                \\
                \dif{g_2}{x_1} & \dif{g_2}{x_2} & \cdots & \dif{g_2}{x_n} \\
                               &                &        &                \\
                \vdots         &                & \ddots & \vdots         \\
                               &                &        &                \\
                \dif{g_m}{x_1} & \dif{g_m}{x_2} & \cdots & \dif{g_m}{x_n}
                \end{bmatrix*} =
 -\begin{bmatrix*}[r]
                \dif{f_1}{z_1} & \dif{f_1}{z_2} & \cdots & \dif{f_1}{z_m} \\
                               &                &        &                \\
                \dif{f_2}{z_1} & \dif{f_2}{z_2} & \cdots & \dif{f_2}{z_m} \\
                               &                &        &                \\
                \vdots         &                & \ddots & \vdots         \\
                               &                &        &                \\
                \dif{f_m}{z_1} & \dif{f_m}{z_2} & \cdots & \dif{f_m}{z_m}
                \end{bmatrix*}^{-1}
  \begin{bmatrix*}[r]
                \dif{f_1}{x_1} & \dif{f_1}{x_2} & \cdots & \dif{f_1}{x_n} \\
                               &                &        &                \\
                \dif{f_2}{x_1} & \dif{f_2}{x_2} & \cdots & \dif{f_2}{x_n} \\
                               &                &        &                \\
                \vdots         &                & \ddots & \vdots         \\
                               &                &        &                \\
                \dif{f_m}{x_1} & \dif{f_m}{x_2} & \cdots & \dif{f_m}{x_n}
                \end{bmatrix*}.            
 \]
Si $F$ es de clase $\mathcal{C}^p, p \ge 1,$ entonces $g$ tambi�n.
 
\end{theorem}

\section{Extremos de funciones a valores reales.} \label{sec:extremos}

\begin{definition} [Extremos locales y globales] \label{def:extremos}
 \mbox{}
 
 Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in A$. Decimos que:
 \begin{itemize}
  \item $f \text{ tiene un \emph{m�ximo local} o \emph{relativo} en } x_o \text{ si } \exists \delta > 0 : f(x_o) \ge f(x) \forall x \in B_{\delta}(x_o) \cap A.$ 
  \item $f \text{ tiene un \emph{m�nimo local} o \emph{relativo} en } x_o \text{ si } \exists \delta > 0 : f(x_o) \le f(x) \forall x \in B_{\delta}(x_o) \cap A.$
  \item $f \text{ tiene un \emph{m�ximo global} o \emph{absoluto} en } x_o \text{ si } f(x_o) \ge f(x) \forall x \in A.$ 
  \item $f \text{ tiene un \emph{m�nimo global} o \emph{absoluto} en } x_o \text{ si } f(x_o) \le f(x) \forall x \in A.$
 \end{itemize}
 Decimos que $f$ tiene un \emph{extremo} en $x_o$ si $f$ tiene un m�ximo o m�nimo (absoluto o relativo) en $x_o$.
 \begin{obs}
  Notemos que todo extremo absoluto es \emph{tambi�n} un extremo relativo. La rec�proca de esta afirmaci�n es falsa (un extremo relativo no tiene por qu� ser absoluto).
 \end{obs}
\end{definition}

\begin{theorem}\textbf{Condici�n necesaria de extremo.} \label{teo:grad_nulo}
 Sea $f: A \subset \Rn{n} \to \R$ diferenciable en alg�n entorno abierto de $x_o \in \interior{(A)}$. Supongamos que $f$ tiene un extremo en $x_o$. Entonces
 \[
  \grad f(x_o) = \mathbf{0}.
 \]
\end{theorem}

\begin{definition} [Punto cr�tico] \label{def:pto_crit}
 Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$. Decimos que $x_o$ es un \emph{punto cr�tico} de $f$ si $f$ no es diferenciable en $x_o$ o $\grad f_{(x_o)} = \mathbf{0}$.
\end{definition}

\begin{definition} [Punto silla] \label{def:pto_silla}
 Sean $f: A \subset \Rn{n} \to \R$ y $x_o \in \interior{(A)}$. Si $x_o$ es un punto cr�tico de $f$ y $f$ no tiene un extremo en $x_o$, decimos que $f$ tiene un \emph{punto silla} en $x_o$.
\end{definition}


\begin{theorem}\textbf{Criterio de la derivada segunda.} \label{teo:derivada_2da}
\mbox{}

 Sean $A \subset \Rn{2}$ un conjunto abierto y $f: A \subset \Rn{2} \to \R$ una funci�n de clase $\mathcal{C}^2$. Sea $(x_o,y_o) \in A$ y supongamos que $\grad f(x_o,y_o) = \mathbf{0}$. Entonces,  
 \begin{enumerate} [I.]
    \item si $\det(\mathbf{H}_f (x_o,y_o)) > 0$ y
    \begin{enumerate}[(a)]
        \item $\pdv[2]{f}{x} (x_o,y_o) > 0$, $f$ tiene un m�nimo local en $(x_o,y_o)$;
        \item $\pdv[2]{f}{x} (x_o,y_o) < 0$, $f$ tiene un m�ximo local en $(x_o,y_o)$;
    \end{enumerate}
    \item si $\det(\mathbf{H}_f (x_o,y_o)) < 0$, $f$ tiene un \emph{punto silla} en $(x_o,y_o)$.
 \end{enumerate}

\end{theorem}

\begin{theorem}\textbf{de los valores extremos de Weierstrass.} \label{teo:weier}difDir
  Sean $A \subset \Rn{n}$ un conjunto cerrado y acotado y $f: A \subset \Rn{n} \to \R$ una funci�n continua. Entonces $f$ alcanza un m�ximo y un m�nimo absoluto en $A$.
\end{theorem}

\begin{theorem} [M�todo de multiplicadores de Lagrange] \label{teo:lagrange}
    Sean $f:U \subset \Rn{n} \to \R$ y $g:U \subset \Rn{n} \to \R$ funciones de clase $\mathcal{C}^1$. Sea $x_o \in U$ y sea $c = g(x_o)$. Sea $S$ el conjunto de nivel $c$ de $g$. Supongamos que $\grad g (x_o) \ne \mathbf{0}$. Si $f|S$ (que denota a la restricci�n de $f$ a $S$) tiene un extremo local en $x_o$, entonces $\exists \lambda \in \R$ tal que
    \[
     \grad f (x_o) = \lambda \grad g (x_o).
    \]
\end{theorem}






% \bibliographystyle{plain}
% \bibliography{volterra}

\end{document}
